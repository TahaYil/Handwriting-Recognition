from sympy import false
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from PIL import Image, ImageOps, ImageEnhance
import torch
import cv2
import numpy as np

# Model ve i≈ülemciyi y√ºkle
processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten', use_fast=False)
model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

# G√∂r√ºnt√ºy√º y√ºkle
image = Image.open("denedene.png")

# G√∂r√ºnt√ºy√º numpy dizisine d√∂n√º≈üt√ºr
image_array = np.array(image)
grayImage = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)

# Otsu Thresholding uygula
# Otsu, e≈üik deƒüerini otomatik olarak belirler
ret, otsu_thresh = cv2.threshold(grayImage, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

# Morfolojik i≈ülemler - harflerdeki kopmalarƒ± birle≈ütirmek i√ßin
# 1. Kapama (Closing) i≈ülemi - kopuk harfleri birle≈ütirir
kernel = np.ones((2, 2), np.uint8)  # Kernel boyutunu metninize g√∂re ayarlayabilirsiniz
closing = cv2.morphologyEx(otsu_thresh, cv2.MORPH_CLOSE, kernel)

# 2. Geni≈ületme (Dilation) i≈ülemi - harfleri daha kalƒ±n yapar, bo≈üluklarƒ± doldurur
dilation_kernel = np.ones((1, 1), np.uint8)
dilated_image = cv2.dilate(closing, dilation_kernel, iterations=1)

# 3. Median filtreleme - g√ºr√ºlt√ºy√º azaltƒ±r
filtered_image = cv2.medianBlur(dilated_image, 3)

# Numpy dizisini PIL Image'e d√∂n√º≈üt√ºr
threshold_image = Image.fromarray(otsu_thresh)
threshold_rgb = threshold_image.convert('RGB')

# G√∂r√ºnt√ºy√º g√∂ster
threshold_rgb.show()

# Modelle i≈ülem i√ßin g√∂r√ºnt√ºy√º hazƒ±rla
pixel_values = processor(images=threshold_rgb, return_tensors="pt").pixel_values

# Tahmin yap
generated_ids = model.generate(pixel_values)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

print("\nüñãÔ∏è Tanƒ±nan Metin:\n")
print(generated_text)